Dataset Link: https://wiki.dbpedia.org/data-set-30
The file contains:
1. SavedModels
2. Encoded_features_revised
3. Encoded_labels_revised
4. Encoding
5. Evaluate
6. Info
7. Rdf_features
8. Spell
9. Temp
10. Train_RF
11.Word2vec_trainer
12.Word2vec_vis

Statistics:
DBpedia dataset3
is first extracted. DBpedia 2016-10 release contains 13 billion pieces of information
out of which 1.7 billion were extracted from the English edition of Wikipedia. Note that, only
1.7 billion RDF triples (English version) are used to evaluate the proposed approach; however,
all syntactically invalid triples are ignored


Declaration:
Authors: Hatem Soliman hatem@nuaa.edu.cn
College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China.


Copyright:
The data does not belong to any organization’s official or private records. It is collected during the experiments of our proposed approach i.e., H-SAGE, and, hence totally basis upon raw facts and figures. Therefore, we can’t endorse any claim about its perfectness, however, it is very effective and feasible for the experimental setups regarding KG-based RecSyss. The authors expect the following ethical norms from the users of these datasets.
1.	Will not divide and distribute without permission
2.	Will not de-anonymize
3.	Will just use for educational purpose


Kind Regards,
Hatem Soliman 
College of Computer Science and Technology,
Nanjing University of Aeronautics and Astronautics,
Nanjing, China.
